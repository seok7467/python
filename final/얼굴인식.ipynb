{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영상 얼굴인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "#     cv2.imshow('Video', frame)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 비디오 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,480) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam.set(4,240) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    "\n",
    "\n",
    "while True:\n",
    "#     sample_num = sample_num + 1\n",
    "    ret_val, img = cam.read() # 캠 이미지 불러오기\n",
    " \n",
    "    cv2.imshow(\"Cam Viewer\",img) # 불러온 이미지 출력하기\n",
    "    cv2.imwrite('C:\\\\dev\\\\eclipse-workspace\\\\.metadata\\\\.plugins\\\\org.eclipse.wst.server.core\\\\tmp1\\\\wtpwebapps\\\\jsp_Fundamental\\\\test\\\\aaa\\\\img.jpg',\n",
    "                img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번 카메라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from time import sleep\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,480) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam.set(4,240) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "s_path='C:\\\\dev\\\\eclipse-workspace\\\\.metadata\\\\.plugins\\\\org.eclipse.wst.server.core\\\\tmp1\\\\wtpwebapps\\\\jsp_Fundamental\\\\test\\\\aaa\\\\'\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read() # 캠 이미지 불러오기\n",
    "    \n",
    "    millis = int(round(time.time() * 1000))\n",
    "    date_r=str(millis-10000)[:-2]\n",
    "    date=str(millis)[:-2]\n",
    "    \n",
    "    cv2.imwrite(s_path+date+'.jpg',img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        \n",
    "    )\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "#     sample_num = sample_num + 1\n",
    "    \n",
    "    cv2.imshow(\"Cam Viewer\",img) # 불러온 이미지 출력하기\n",
    "    \n",
    "    \n",
    "    sleep(0.05)\n",
    "    if os.path.isfile(s_path+date_r+'.jpg'):\n",
    "        os.remove(s_path+date_r+'.jpg')\n",
    "        \n",
    "    if os.path.isfile(s_path+date_r+'.jpg'):\n",
    "        os.remove(s_path+date_r+'.jpg')\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번 카메라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from time import sleep\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "cam.set(3,480) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam.set(4,240) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "s_path='C:\\\\dev\\\\eclipse-workspace\\\\.metadata\\\\.plugins\\\\org.eclipse.wst.server.core\\\\tmp1\\\\wtpwebapps\\\\jsp_Fundamental\\\\test\\\\bbb\\\\'\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read() # 캠 이미지 불러오기\n",
    "    \n",
    "    millis = int(round(time.time() * 1000))\n",
    "    date_r=str(millis-10000)[:-2]\n",
    "    date=str(millis)[:-2]\n",
    "    \n",
    "    cv2.imwrite(s_path+date+'.jpg',img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        \n",
    "    )\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "#     sample_num = sample_num + 1\n",
    "    \n",
    "    cv2.imshow(\"Cam Viewer\",img) # 불러온 이미지 출력하기\n",
    "    \n",
    "    \n",
    "    sleep(0.05)\n",
    "    if os.path.isfile(s_path+date_r+'.jpg'):\n",
    "        os.remove(s_path+date_r+'.jpg')\n",
    "        \n",
    "    if os.path.isfile(s_path+date_r+'.jpg'):\n",
    "        os.remove(s_path+date_r+'.jpg')\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번 2번 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from time import sleep\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "cam1 = cv2.VideoCapture(0)\n",
    "cam1.set(3,480) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam1.set(4,240) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    "\n",
    "cam2 = cv2.VideoCapture(1)\n",
    "cam2.set(3,480) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam2.set(4,240) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    "\n",
    "s_path1='C:\\\\dev\\\\eclipse-workspace\\\\.metadata\\\\.plugins\\\\org.eclipse.wst.server.core\\\\tmp1\\\\wtpwebapps\\\\jsp_Fundamental\\\\test\\\\aaa\\\\'\n",
    "s_path2='C:\\\\dev\\\\eclipse-workspace\\\\.metadata\\\\.plugins\\\\org.eclipse.wst.server.core\\\\tmp1\\\\wtpwebapps\\\\jsp_Fundamental\\\\test\\\\bbb\\\\'\n",
    "while True:\n",
    "    \n",
    "    millis = int(round(time.time() * 1000))\n",
    "    date_r=str(millis-10000)[:-2]\n",
    "    date=str(millis)[:-2]\n",
    "    \n",
    "    \n",
    "    ret_val1, img1 = cam1.read() # 캠 이미지 불러오기\n",
    "    ret_val2, img2 = cam2.read()\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    cv2.imwrite(s_path1+date+'.jpg',img1)\n",
    "    cv2.imwrite(s_path2+date+'.jpg',img2)\n",
    "    \n",
    "    sleep(0.05)\n",
    "    cv2.imshow(\"Cam Viewer\",img1)\n",
    "    \n",
    "    if os.path.isfile(s_path1+date_r+'.jpg'):\n",
    "        os.remove(s_path1+date_r+'.jpg')\n",
    "        \n",
    "    if os.path.isfile(s_path1+date_r+'.jpg'):\n",
    "        os.remove(s_path1+date_r+'.jpg')\n",
    "        \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam1.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from time import sleep\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,480) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam.set(4,240) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    "s_path='C:\\\\dev\\\\eclipse-workspace\\\\.metadata\\\\.plugins\\\\org.eclipse.wst.server.core\\\\tmp1\\\\wtpwebapps\\\\jsp_Fundamental\\\\test\\\\aaa\\\\'\n",
    "\n",
    "while True:\n",
    "    millis = int(round(time.time() * 1000))\n",
    "    date_r=str(millis-10000)\n",
    "    date=str(millis)\n",
    "#     sample_num = sample_num + 1\n",
    "    ret_val, img = cam.read() # 캠 이미지 불러오기\n",
    " \n",
    "    cv2.imshow(\"Cam Viewer\",img) # 불러온 이미지 출력하기\n",
    "    cv2.imwrite(s_path+date+'.jpg',img)\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(s_path+date_r+'.jpg'):\n",
    "        os.remove(s_path+date_r+'.jpg')\n",
    "  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10_08_21'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now.strftime('%H_%M_%S')\n",
    "# now.strftime('%H_%M_%S_%f')[:-3]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595554842\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "millis = int(round(time.time() * 1000))\n",
    "date=str(millis)[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "url = 'http://localhost:8080/webcamjs-master/demos/basic2.html'\n",
    "\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP카메라 영상 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-15d5c3dab5f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('http://127.0.0.1:8080/webcamjs-master/demos/basic2.html')\n",
    "\n",
    "while(True):\n",
    "   \n",
    "    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영상 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, 20.0, (640,480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "#         frame = cv2.flip(frame,0)\n",
    "\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('output.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame',gray)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프레임단위 영상 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "#Below code will capture the video frames and will sve it a folder (in current working directory)\n",
    "\n",
    "dirname = 'final'\n",
    "#video path\n",
    "cap = cv2.VideoCapture(\"output.mp4\")\n",
    "count = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    else:\n",
    "        cv2.imshow('frame', frame)\n",
    "        #The received \"frame\" will be saved. Or you can manipulate \"frame\" as per your needs.\n",
    "        name = \"rec_frame\"+str(count)+\".jpg\"\n",
    "        cv2.imwrite(os.path.join(dirname,name), frame)\n",
    "        count += 1\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 55  908k   55  506k    0     0   773k      0  0:00:01 --:--:--  0:00:01  772k\n",
      "100  908k  100  908k    0     0  1184k      0 --:--:-- --:--:-- --:--:-- 1182k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./haarcascade_frontalface_default.xml https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img_source = \"1.jpg\"\n",
    "\n",
    "img = cv2.imread(img_source)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    ")\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('OMG',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
